{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analyze trained models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rader et al. 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "\n",
    "import palettable.scientific.sequential\n",
    "import importlib as imp\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import experiments\n",
    "import base_directories\n",
    "import tensorflow as tf\n",
    "import build_model\n",
    "import build_data\n",
    "import plots\n",
    "import metrics\n",
    "import pickle\n",
    "import save_load_model_run\n",
    "import silence_tensorflow.auto\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "dir_settings = base_directories.get_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp.reload(experiments)\n",
    "exp_name = \"exp000\"\n",
    "settings = experiments.get_experiment(exp_name)\n",
    "settings[\"rng_seed\"] = 34  # 23, 34, 45\n",
    "settings[\"model_type\"] = \"interp_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get training / validation / testing data\n",
    "(\n",
    "    analog_input,\n",
    "    analog_output,\n",
    "    soi_train_input,\n",
    "    soi_train_output,\n",
    "    soi_val_input,\n",
    "    soi_val_output,\n",
    "    soi_test_input,\n",
    "    soi_test_output,\n",
    "    input_standard_dict,\n",
    "    output_standard_dict,\n",
    "    lat,\n",
    "    lon,\n",
    ") = build_data.build_data(settings, dir_settings[\"data_directory\"])\n",
    "\n",
    "print(soi_test_input.shape)\n",
    "print(analog_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD THE TRAINED MODEL\n",
    "tf.keras.backend.clear_session()\n",
    "savename_prefix = (\n",
    "        exp_name\n",
    "        + \"_\" + settings[\"model_type\"] + \"_\"\n",
    "        + f\"rng_seed_{settings['rng_seed']}\"\n",
    ")\n",
    "settings[\"savename_prefix\"] = savename_prefix\n",
    "\n",
    "model = save_load_model_run.load_model(settings, settings[\"savename_prefix\"], [soi_train_input, analog_input])\n",
    "\n",
    "mask_model = model.get_layer('mask_model')\n",
    "dissimilarity_model = model.get_layer('dissimilarity_model')\n",
    "prediction_model = model.get_layer('prediction_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = build_data.batch_generator(settings, soi_train_input, soi_train_output,\n",
    "                                  analog_input, analog_output, batch_size=1_000, rng_seed=settings[\"rng_seed\"])\n",
    "x_input_train, target_train = next(gen)\n",
    "gen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp.reload(plots)\n",
    "\n",
    "(weights_train,\n",
    " dissimilarities_train,\n",
    " prediction_train,\n",
    " ) = build_model.parse_model([x_input_train[0], x_input_train[1]], mask_model, dissimilarity_model, prediction_model)\n",
    "\n",
    "# PLOT THE MASKS AND THEIR VARIANCE\n",
    "\n",
    "# Training mean mask\n",
    "fig = plt.figure(figsize=(15, 5*2))\n",
    "ax1, climits = plots.plot_interp_masks(fig, settings, weights_train[:, :, :, 0].mean(axis=0), lat=lat, lon=lon, central_longitude=215., title_text=\"(a) Mask for Channel 0\", subplot=(2, 2, 1))\n",
    "ax2 = plots.plot_interp_masks(fig, settings, weights_train[:, :, :, 1].mean(axis=0), lat=lat, lon=lon, central_longitude=215., climits=climits, title_text=\"(b) Mask for Channel 1\", subplot=(2, 2, 2))\n",
    "\n",
    "# Validation mean mask\n",
    "ax3, climits = plots.plot_interp_masks(fig, settings, weights_train[:, :, :, 0].var(axis=0), lat=lat, lon=lon,\n",
    "                                       central_longitude=215., title_text=\"(c) Variance of Mask for Channel 0\",\n",
    "                                       subplot=(2, 2, 3), )\n",
    "ax4, climits = plots.plot_interp_masks(fig, settings, weights_train[:, :, :, 1].var(axis=0), lat=lat, lon=lon,\n",
    "                                       central_longitude=215., climits=climits, title_text=\"(d) Variance of Mask for Channel 1\",\n",
    "                                       subplot=(2, 2, 4), )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('UNIQUE MASK SUMS = ' + str(np.unique(np.sum(weights_train[:,:,:,:],axis=(1,2,3))).round(1)))\n",
    "print('UNIQUE MASK NORMALIZED SUMS = ' + str(np.unique(np.sum(weights_train[:,:,:,:],axis=(1,2,3))/(len(lat)*len(lon))).round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "y_predict = model.predict([x_input_train[0], x_input_train[1]])\n",
    "_ = gc.collect()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y_predict)\n",
    "plt.title('histogram of training predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synthetic_similarities = np.arange(0,np.max(dissimilarities_train)*1.1,.01)\n",
    "prediction = prediction_model([synthetic_similarities])\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(synthetic_similarities,prediction,'.')\n",
    "plt.xlabel('input dissimilarity values')\n",
    "plt.ylabel('output prediction')\n",
    "plt.title('training range: ' + str((np.min(dissimilarities_train).round(3), np.max(dissimilarities_train).round(3))))\n",
    "plt.show()\n",
    "\n",
    "print((np.min(dissimilarities_train), np.max(dissimilarities_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# error('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # MAKE SUMMARY PLOT ACROSS ALL MODEL TYPES\n",
    "# rng_string = settings[\"savename_prefix\"][settings[\"savename_prefix\"].find('rng'):]\n",
    "#\n",
    "# plt.figure(figsize=(8, 4 * 3))\n",
    "# for i_rng, rng_string in enumerate((\"rng_seed_\" + str(settings[\"rng_seed_list\"][0]),\n",
    "#                                     \"rng_seed_\" + str(settings[\"rng_seed_list\"][1]),\n",
    "#                                     \"rng_seed_\" + str(settings[\"rng_seed_list\"][2]),\n",
    "#                                     )):\n",
    "#     # GET THE METRICS DATA\n",
    "#     with open(dir_settings[\"metrics_directory\"] + settings[\n",
    "#         \"exp_name\"] + \"_interp_model_\" + rng_string + '_metrics.pickle', 'rb') as f:\n",
    "#         plot_metrics = pickle.load(f)\n",
    "#     with open(dir_settings[\"metrics_directory\"] + settings[\n",
    "#         \"exp_name\"] + '_ann_model_' + rng_string + '_metrics.pickle', 'rb') as f:\n",
    "#         ann_metrics = pickle.load(f)\n",
    "#     with open(dir_settings[\"metrics_directory\"] + settings[\n",
    "#         \"exp_name\"] + '_ann_analog_model_' + rng_string + '_metrics.pickle', 'rb') as f:\n",
    "#         ann_analog_metrics = pickle.load(f)\n",
    "#\n",
    "#     # PLOT THE METRICS\n",
    "#     plt.subplot(3, 1, i_rng + 1)\n",
    "#\n",
    "#     plots.summarize_skill_score(plot_metrics)\n",
    "#\n",
    "#     plot_ann_metrics = ann_metrics\n",
    "#     y_plot = 1. - metrics.eval_function(plot_ann_metrics[\"error_network\"]) / metrics.eval_function(\n",
    "#         plot_ann_metrics[\"error_climo\"])\n",
    "#     plt.axhline(y=y_plot, linestyle='--', color=\"teal\", alpha=.8, label=\"vanilla ann\")\n",
    "#\n",
    "#     plot_ann_metrics = ann_analog_metrics\n",
    "#     y_plot = 1. - metrics.eval_function(plot_ann_metrics[\"error_network\"]) / metrics.eval_function(\n",
    "#         plot_ann_metrics[\"error_climo\"])\n",
    "#     plt.plot(plot_ann_metrics[\"analogue_vector\"], y_plot, '-', color=\"teal\", alpha=.8, label=\"ann analogue\")\n",
    "#\n",
    "#     plt.text(0.0, .99, ' ' + settings[\"exp_name\"] + \"_interp_model_\" + rng_string + '\\n smooth_time: ['\n",
    "#              + str(settings[\"smooth_len_input\"]) + ', ' + str(settings[\"smooth_len_output\"]) + '], leadtime: '\n",
    "#              + str(settings[\"lead_time\"]),\n",
    "#              fontsize=6, color=\"gray\", va=\"top\", ha=\"left\", fontfamily=\"monospace\",\n",
    "#              transform=plt.gca().transAxes)\n",
    "#     plt.grid(False)\n",
    "#     plt.ylim(-.4, .4)\n",
    "#     plt.legend(fontsize=6, loc=4)\n",
    "#\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(dir_settings[\"figure_directory\"] + 'metric_summaries/' + settings[\"exp_name\"]\n",
    "#                 + \"multiple_rng\" + '_skill_score_vs_nanalogues.png',\n",
    "#                 dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp.reload(plots)\n",
    "import gc\n",
    "\n",
    "CMAP = \"RdBu_r\"\n",
    "\n",
    "n_analogues = 15\n",
    "n_rows = 5 + 2#n_analogues + 2\n",
    "n_testing_soi = soi_test_input.shape[0]\n",
    "n_testing_analogs = analog_input.shape[0]\n",
    "rng_eval = np.random.default_rng(settings[\"rng_seed\"])\n",
    "i_soi = rng_eval.choice(np.arange(0, soi_test_input.shape[0]), n_testing_soi, replace=False)\n",
    "i_analog = rng_eval.choice(np.arange(0, analog_input.shape[0]), n_testing_analogs, replace=False)\n",
    "\n",
    "x_input_test = [soi_test_input[i_soi,:,:,:], analog_input[i_analog,:,:,:]]\n",
    "x_output_test = [soi_test_output[i_soi], analog_output[i_analog]]\n",
    "\n",
    "# PLOT THE MASKS AND THEIR VARIANCE\n",
    "\n",
    "# Training mean mask\n",
    "for sample in (13, 44, 201):\n",
    "    prediction_test = model.predict(\n",
    "        [np.broadcast_to(x_input_test[0][sample:sample+1],\n",
    "                         (x_input_test[1].shape[0],\n",
    "                          x_input_test[1].shape[1],\n",
    "                          x_input_test[1].shape[2],\n",
    "                          x_input_test[1].shape[3])), x_input_test[1]\n",
    "         ], batch_size=10_000,)\n",
    "    __ = gc.collect()\n",
    "    min_index = np.concatenate(np.argsort(prediction_test, axis=0))[:n_analogues]\n",
    "    y_truth = str(np.round(x_output_test[0][sample],3))\n",
    "    y_predict = str(np.round(x_output_test[1][min_index].mean(),3))\n",
    "    print(y_truth, y_predict)\n",
    "\n",
    "    for masked in (True, False):\n",
    "        fig = plt.figure(figsize=(15, 4.5*n_rows), dpi=100)\n",
    "        if masked:\n",
    "            mask = weights_train.mean(axis=0)\n",
    "            mask = np.where(mask<np.max(mask[:])*.15, 0., 1.)\n",
    "            mask_channel0 = mask[:,:,0]\n",
    "            mask_channel1 = mask[:,:,1]\n",
    "        else:\n",
    "            mask_channel0 = np.ones((weights_train.shape[1],weights_train.shape[2]))\n",
    "            mask_channel1 = np.ones((weights_train.shape[1],weights_train.shape[2]))\n",
    "\n",
    "        __, climits = plots.plot_interp_masks(fig, settings, mask_channel0*weights_train[:,:,:,0].mean(axis=0), lat=lat, lon=lon, central_longitude=215.,\n",
    "                                              title_text=f\"(a) Mask Channel 0\", subplot=(n_rows, 2, 1))\n",
    "        __, climits = plots.plot_interp_masks(fig, settings, mask_channel1*weights_train[:,:,:,1].mean(axis=0), lat=lat, lon=lon, central_longitude=215.,\n",
    "                                              climits=climits, title_text=f\"(b) Mask Channel 1\", subplot=(n_rows, 2, 2))\n",
    "\n",
    "        __, climits = plots.plot_interp_masks(fig, settings, mask_channel0*x_input_test[0][sample,:,:,0], lat=lat, lon=lon, central_longitude=215.,\n",
    "                                              climits=(-3,3), title_text=f\"(a) SOI #{sample}; Channel 0; Truth={y_truth}, Predicted={y_predict}\", subplot=(n_rows, 2, 3), cmap=CMAP)\n",
    "        __, climits = plots.plot_interp_masks(fig, settings, mask_channel1*x_input_test[0][sample,:,:,1], lat=lat, lon=lon, central_longitude=215.,\n",
    "                                              climits=climits, title_text=f\"(b) SOI #{sample}; Channel 1\", subplot=(n_rows, 2, 4), cmap=CMAP)\n",
    "\n",
    "        for i_analog in np.arange(0,n_rows-2):\n",
    "            __, climits = plots.plot_interp_masks(fig, settings, mask_channel0*x_input_test[1][min_index[i_analog],:,:,0], lat=lat, lon=lon, central_longitude=215.,\n",
    "                                                  climits=climits, title_text=f\"(a) Analog #{min_index[i_analog]}; Channel 0\", subplot=(n_rows, 2, 5+i_analog*2), cmap=CMAP)\n",
    "            __, climits = plots.plot_interp_masks(fig, settings, mask_channel1*x_input_test[1][min_index[i_analog],:,:,1], lat=lat, lon=lon, central_longitude=215.,\n",
    "                                                  climits=climits, title_text=f\"(b) Analog #{min_index[i_analog]}; Channel 1\", subplot=(n_rows, 2, 6+i_analog*2), cmap=CMAP)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_settings[\"figure_directory\"] + 'case_studies/' + settings[\"savename_prefix\"]\n",
    "                    + '_casestudymaps_mask' + str(masked) + '_sample' + str(sample) + '.png', dpi=300, bbox_inches='tight')\n",
    "        # plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD THE TRAINED MODEL\n",
    "tf.keras.backend.clear_session()\n",
    "savename_prefix = (\n",
    "        exp_name\n",
    "        + \"_\" + \"ann_model\" + \"_\"\n",
    "        + f\"rng_seed_{settings['rng_seed']}\"\n",
    ")\n",
    "settings[\"savename_prefix\"] = savename_prefix\n",
    "\n",
    "model = save_load_model_run.load_model(settings, settings[\"savename_prefix\"], [soi_train_input, analog_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xai\n",
    "imp.reload(xai)\n",
    "#---------------------------------------\n",
    "# Gradient x Input\n",
    "#---------------------------------------\n",
    "# compute the multiplication of gradient * inputs\n",
    "# and reshape into a map of latitude x longitude\n",
    "top_pred_idx = 0\n",
    "soi_input = soi_test_input\n",
    "soi_output = soi_test_output\n",
    "\n",
    "grads = xai.get_gradients(model,soi_input,top_pred_idx).numpy()\n",
    "grad_x_input = grads * soi_input\n",
    "# grad_x_input = grad_x_input.reshape((soi_input.shape[0],soi_input.shape[1],soi_input.shape[2]))\n",
    "print(np.shape(grad_x_input))\n",
    "\n",
    "grad_x_input = np.abs(grad_x_input)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4.5*n_rows), dpi=100)\n",
    "__, climits = plots.plot_interp_masks(fig, settings, grad_x_input[:,:,:,0].mean(axis=0), lat=lat, lon=lon, central_longitude=215., title_text=f\"(a) XAI Channel 0\", subplot=(n_rows, 2, 1),climits=(0, .0075))\n",
    "\n",
    "__, climits = plots.plot_interp_masks(fig, settings, grad_x_input[:,:,:,1].mean(axis=0), lat=lat, lon=lon, central_longitude=215., title_text=f\"(a) XAI Channel 1\", subplot=(n_rows, 2, 2),climits=climits)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(dir_settings[\"figure_directory\"] + 'case_studies/' + settings[\"savename_prefix\"]\n",
    "            + '_xai_mean.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import model_diagnostics\n",
    "# import metrics\n",
    "#\n",
    "# imp.reload(model_diagnostics)\n",
    "# imp.reload(plots)\n",
    "# imp.reload(metrics)\n",
    "# rng_eval = np.random.default_rng(settings[\"rng_seed\"])\n",
    "#\n",
    "# for n_testing_analogs in (1000,):\n",
    "#     for n_testing_soi in (250,):\n",
    "#         print('---' + str((n_testing_soi, n_testing_analogs)) + '---')\n",
    "#\n",
    "#         i_soi = rng_eval.choice(np.arange(0, soi_test_input.shape[0]), n_testing_soi, replace=False)\n",
    "#         i_analog = rng_eval.choice(np.arange(0, analog_train_input.shape[0]), n_testing_analogs, replace=False)\n",
    "#\n",
    "#         metrics_dict = model_diagnostics.assess_metrics(settings, model,\n",
    "#                                                         soi_test_input[i_soi, :, :, :],\n",
    "#                                                         soi_test_output[i_soi],\n",
    "#                                                         analog_train_input[i_analog, :, :, :],\n",
    "#                                                         analog_train_output[i_analog],\n",
    "#                                                         lat, lon,\n",
    "#                                                         mask=np.mean(weights_train, axis=0)[np.newaxis, :, :, :],\n",
    "#                                                         analogue_vector=[1, 2, 5, 10, 15, 20, 30, 50, 75],\n",
    "#                                                         show_figure=True,\n",
    "#                                                         save_figure=False,\n",
    "#                                                         )\n",
    "#\n",
    "#         with open(dir_settings[\"metrics_directory\"]+settings[\"savename_prefix\"]+'_metrics_testing.pickle', 'wb') as f:\n",
    "#             pickle.dump(metrics_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model_diagnostics_orig\n",
    "import metrics\n",
    "import importlib as imp\n",
    "from timebudget import timebudget\n",
    "\n",
    "imp.reload(model_diagnostics_orig)\n",
    "imp.reload(plots)\n",
    "imp.reload(metrics)\n",
    "\n",
    "# metrics_dict = model_diagnostics.assess_metrics(settings, model,\n",
    "#                                                 soi_train_input[:200,:,:,:],\n",
    "#                                                 soi_train_output[:200],\n",
    "#                                                 analog_input[:1000,:,:,:],\n",
    "#                                                 analog_output[:1000],\n",
    "#                                                 lat, lon,\n",
    "#                                                 mask=np.mean(weights_train, axis=0)[np.newaxis, :, :, :],\n",
    "#                                                 analogue_vector=[15,],\n",
    "#                                                 show_figure=False,\n",
    "#                                                 save_figure=False,\n",
    "#                                                 )\n",
    "metrics_dict = model_diagnostics_orig.assess_metrics(settings, model,\n",
    "                                                soi_train_input[:500,:,:,:],\n",
    "                                                soi_train_output[:500],\n",
    "                                                analog_input[:500,:,:,:],\n",
    "                                                analog_output[:500],\n",
    "                                                lat, lon,\n",
    "                                                mask=np.mean(weights_train, axis=0)[np.newaxis, :, :, :],\n",
    "                                                analogue_vector=[15,],\n",
    "                                                show_figure=False,\n",
    "                                                save_figure=False,\n",
    "                                                )\n",
    "# metrics_dict = model_diagnostics.assess_metrics(settings, model,\n",
    "#                                                 soi_train_input[:200,:,:,0:1],\n",
    "#                                                 soi_train_output[:200],\n",
    "#                                                 analog_input[:1000,:,:,0:1],\n",
    "#                                                 analog_output[:1000],\n",
    "#                                                 lat, lon,\n",
    "#                                                 mask=np.ones(shape=(1,96,192,2)),\n",
    "#                                                 analogue_vector=[15,],\n",
    "#                                                 show_figure=False,\n",
    "#                                                 save_figure=False,\n",
    "#                                                 )\n",
    "\n",
    "        # with open(dir_settings[\"metrics_directory\"]+settings[\"savename_prefix\"]+'_metrics_testing.pickle', 'wb') as f:\n",
    "        #     pickle.dump(metrics_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model_diagnostics\n",
    "import metrics\n",
    "import importlib as imp\n",
    "from timebudget import timebudget\n",
    "\n",
    "imp.reload(model_diagnostics)\n",
    "imp.reload(plots)\n",
    "imp.reload(metrics)\n",
    "\n",
    "metrics_dict = model_diagnostics.assess_metrics(settings, model,\n",
    "                                                soi_train_input[:500,:,:,:],\n",
    "                                                soi_train_output[:500],\n",
    "                                                analog_input[:500,:,:,:],\n",
    "                                                analog_output[:500],\n",
    "                                                lat, lon,\n",
    "                                                mask=np.mean(weights_train, axis=0)[np.newaxis, :, :, :],\n",
    "                                                analogue_vector=[15,],\n",
    "                                                show_figure=False,\n",
    "                                                save_figure=False,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "077f9de2ae6c96b973529eca1b9ed06ef1edc815a3832513fa5e5425102809d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
